# GenETL Optimized Docker Setup
# Faster loading with simplified health checks

x-airflow-common:
  &airflow-common
  image: apache/airflow:2.7.1-python3.11
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}/${POSTGRES_DB}
    AIRFLOW__CELERY__BROKER_URL: redis://:@genetl-redis:6379/0
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'true'
    # SQLAlchemy compatibility fix
    AIRFLOW__CORE__ENABLE_XCOM_PICKLING: 'false'
    AIRFLOW__CORE__ALLOWED_DESERIALIZATION_CLASSES: 'airflow.*'
    SQLALCHEMY_SILENCE_UBER_WARNING: '1'
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./include:/opt/airflow/include
  user: "${AIRFLOW_UID:-50000}:0"
  depends_on:
    &airflow-common-depends-on
    genetl-redis:
      condition: service_healthy
    genetl-postgres:
      condition: service_healthy
  networks:
    - genetl-net

services:
  # PostgreSQL Database
  genetl-postgres:
    image: postgres:15-alpine
    container_name: genetl-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5450:5432"
    volumes:
      - genetl_postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 3s
      retries: 3
      start_period: 10s
    networks:
      - genetl-net

  # Redis Cache
  genetl-redis:
    image: redis:7-alpine
    container_name: genetl-redis
    restart: unless-stopped
    ports:
      - "6390:6379"
    volumes:
      - genetl_redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 3
      start_period: 5s
    networks:
      - genetl-net

  # Airflow Init
  airflow-init:
    <<: *airflow-common
    container_name: genetl-airflow-init
    entrypoint: /bin/bash
    command:
      - -c
      - |
        echo "Installing additional dependencies..."
        pip install --no-cache-dir \
          apache-airflow-providers-postgres \
          apache-airflow-providers-redis \
          pandas numpy requests psycopg2-binary \
          "SQLAlchemy>=1.4.24,<1.5" great-expectations \
          "redis>=5.0.0" scikit-learn openai
        
        echo "Starting Airflow initialization..."
        mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins
        chown -R "$${AIRFLOW_UID}:0" /opt/airflow/{logs,dags,plugins}
        
        echo "Initializing Airflow database..."
        airflow db migrate
        
        echo "Creating admin user..."
        airflow users create \
          --username admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com \
          --password admin || true
        
        echo "Airflow initialization completed successfully!"
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-admin}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-admin}
    user: "0:0"
    restart: "no"

  # Airflow Webserver
  airflow-webserver:
    <<: *airflow-common
    container_name: genetl-airflow-webserver
    command: webserver
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

  # Airflow Scheduler
  airflow-scheduler:
    <<: *airflow-common
    container_name: genetl-airflow-scheduler
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname \"$${HOSTNAME}\""]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s
    restart: always
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully

volumes:
  genetl_postgres_data:
    name: genetl_postgres_data
  genetl_redis_data:
    name: genetl_redis_data

networks:
  genetl-net:
    name: genetl-network
    driver: bridge